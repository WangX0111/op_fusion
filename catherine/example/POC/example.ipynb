{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "获取硬件信息，如内存大小，缓存级别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlir.ir import Context, Module\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import gc, sys, os, tempfile\n",
    "# from mlir import ir\n",
    "from mlir.ir import *\n",
    "from mlir.dialects import builtin\n",
    "from mlir.dialects import func\n",
    "from mlir.dialects import linalg\n",
    "from mlir.passmanager import *\n",
    "# from mlir import runtime as rt\n",
    "from mlir.runtime import *\n",
    "# from mlir import execution_engine\n",
    "from mlir.execution_engine import *\n",
    "from mlir.dialects.linalg.opdsl import lang as dsl\n",
    "\n",
    "import mlir.dialects.gpu\n",
    "import mlir.dialects.gpu.passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGPU(module):\n",
    "  pm = PassManager()\n",
    "  # pm.add('gpu-kernel-outlining')\n",
    "  pm.add(\"func.func(convert-linalg-to-parallel-loops)\")\n",
    "  # # pm.add(\"test-gpu-greedy-parallel-loop-mapping\")\n",
    "  pm.add(\"convert-parallel-loops-to-gpu\")\n",
    "  pm.add(\"gpu-kernel-outlining\")\n",
    "  pm.add(\"func.func(lower-affine)\")\n",
    "  pm.add(\"func.func(convert-scf-to-cf)\")\n",
    "  pm.add(\"func.func(arith-expand)\")\n",
    "  pm.add(\"func.func(memref-expand)\")\n",
    "  pm.add(\"convert-vector-to-llvm\")\n",
    "  pm.add(\"finalize-memref-to-llvm\")\n",
    "  pm.add(\"func.func(canonicalize)\")\n",
    "  # print(pm)\n",
    "  pm.run(module)\n",
    "  # print(module)\n",
    "\n",
    "  pm = PassManager.parse('builtin.module(gpu.module(strip-debuginfo,convert-gpu-to-nvvm,gpu-to-cubin))')\n",
    "  # print(pm)\n",
    "  pm.run(module)\n",
    "  # print(module)\n",
    "\n",
    "  pm = PassManager()\n",
    "  pm.add(\"gpu-to-llvm\")\n",
    "  # print(pm)\n",
    "  pm.run(module)\n",
    "  # print(module)\n",
    "  return module\n",
    "\n",
    "def transform(module):\n",
    "  # TODO: Allow cloning functions from one module to another.\n",
    "  # Atm we have to resort to string concatenation.\n",
    "\n",
    "  pm = PassManager('builtin.module')\n",
    "  pm.add(\"func.func(convert-linalg-to-loops)\")\n",
    "  pm.add(\"func.func(lower-affine)\")\n",
    "  pm.add(\"func.func(convert-math-to-llvm)\")\n",
    "  pm.add(\"func.func(convert-scf-to-cf)\")\n",
    "  pm.add(\"func.func(arith-expand)\")\n",
    "  pm.add(\"func.func(memref-expand)\")\n",
    "  pm.add(\"convert-vector-to-llvm\")\n",
    "  pm.add(\"finalize-memref-to-llvm\")\n",
    "  pm.add(\"convert-func-to-llvm\")\n",
    "  pm.add(\"reconcile-unrealized-casts\")\n",
    "  pm.run(module)\n",
    "  return module\n",
    "\n",
    "def run(f):\n",
    "  print(\"\\nTEST:\", f.__name__)\n",
    "  f()\n",
    "  gc.collect()\n",
    "  assert Context._get_live_count() == 0\n",
    "  return f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=10000\n",
    "K=500\n",
    "N=1000\n",
    "matmul_expr = r\"\"\"\n",
    "  module  {\n",
    "    func.func @matmul(%a : memref<?x?xf32>, %b : memref<?x?xf32>, %c : memref<?x?xf32>) attributes {llvm.emit_c_interface} {\n",
    "      linalg.matmul \n",
    "        ins(%a, %b: memref<?x?xf32>, memref<?x?xf32>)\n",
    "       outs(%c:memref<?x?xf32>)\n",
    "      return\n",
    "      }\n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMatmul():\n",
    "  with Context() as ctx:\n",
    "    # IR construction using `ctx` as context.\n",
    "\n",
    "    # For example, parsing an MLIR module from string requires the context.\n",
    "    module = Module.parse(matmul_expr)\n",
    "    \n",
    " \n",
    "    arg1 = np.random.randn(M, K).astype(np.float32)\n",
    "    arg2 = np.random.randn(K, N).astype(np.float32)\n",
    "    res = np.zeros((M, N), dtype=arg1.dtype)\n",
    "\n",
    "    arg1_memref_ptr = ctypes.pointer(\n",
    "        ctypes.pointer(get_ranked_memref_descriptor(arg1)))\n",
    "    arg2_memref_ptr = ctypes.pointer(\n",
    "        ctypes.pointer(get_ranked_memref_descriptor(arg2)))\n",
    "    res_memref_ptr = ctypes.pointer(\n",
    "        ctypes.pointer(get_ranked_memref_descriptor(res)))\n",
    "    # print(transform(module))\n",
    "    execution_engine = ExecutionEngine(transform(module))\n",
    "    try:\n",
    "        execution_engine.invoke(\"matmul\", arg1_memref_ptr, arg2_memref_ptr,\n",
    "                                res_memref_ptr)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Got RuntimeError: \", e)\n",
    "    # print(res)\n",
    "    \n",
    "    npout = ranked_memref_to_numpy(res_memref_ptr[0])\n",
    "\n",
    "    print(npout)\n",
    "\n",
    "    print(np.allclose(np.matmul(arg1, arg2), res))\n",
    "\n",
    "testMatmul()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在CPU上\n",
    "8m46.4s\n",
    "运行环境受限，无法指定在GPU上运行\n",
    "引入IREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMatmulGPU():\n",
    "  with Context() as ctx:\n",
    "    # IR construction using `ctx` as context.\n",
    "\n",
    "    # For example, parsing an MLIR module from string requires the context.\n",
    "    module = Module.parse(matmul_expr)\n",
    "    \n",
    " \n",
    "    arg1 = np.random.randn(M, K).astype(np.float32)\n",
    "    arg2 = np.random.randn(K, N).astype(np.float32)\n",
    "    res = np.zeros((M, N), dtype=arg1.dtype)\n",
    "\n",
    "    arg1_memref_ptr = ctypes.pointer(\n",
    "        ctypes.pointer(get_ranked_memref_descriptor(arg1)))\n",
    "    arg2_memref_ptr = ctypes.pointer(\n",
    "        ctypes.pointer(get_ranked_memref_descriptor(arg2)))\n",
    "    res_memref_ptr = ctypes.pointer(\n",
    "        ctypes.pointer(get_ranked_memref_descriptor(res)))\n",
    "    # print(transform(module))\n",
    "    # print(toGPU(module))\n",
    "\n",
    "    shared_libs = [\n",
    "          \"../../../../llvm-project/build/lib/libmlir_runner_utils.so\",\n",
    "          \"../../../../llvm-project/build/lib/libmlir_c_runner_utils.so\",\n",
    "          \"../../../../llvm-project/build/lib/libmlir_cuda_runtime.so\"\n",
    "      ]\n",
    "\n",
    "    execution_engine = ExecutionEngine(toGPU(module),opt_level=3,shared_libs=shared_libs)\n",
    "    try:\n",
    "        execution_engine.invoke(\"matmul\", arg1_memref_ptr, arg2_memref_ptr,\n",
    "                                res_memref_ptr)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Got RuntimeError: \", e)\n",
    "    # print(res)\n",
    "    \n",
    "    # npout = ranked_memref_to_numpy(res_memref_ptr[0])\n",
    "\n",
    "    # print(npout)\n",
    "\n",
    "    # print(np.allclose(np.matmul(arg1, arg2), res))\n",
    "\n",
    "testMatmulGPU()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入IREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import logging\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "import unittest\n",
    "\n",
    "import iree.compiler.tools\n",
    "\n",
    "from iree.compiler import ir\n",
    "from iree.compiler import passmanager\n",
    "from iree.compiler.transforms import ireec\n",
    "# The compiler re-exports API access to a number of dialects. If one of these\n",
    "# fails to import, it indicates a build issue.\n",
    "from iree.compiler.dialects import arith\n",
    "#from iree.compiler.dialects import chlo\n",
    "#from iree.compiler.dialects import mhlo\n",
    "from iree.compiler.dialects import iree_input\n",
    "from iree.compiler.dialects import builtin\n",
    "from iree.compiler.dialects import linalg\n",
    "from iree.compiler.dialects import math\n",
    "from iree.compiler.dialects import memref\n",
    "from iree.compiler.dialects import pdl\n",
    "from iree.compiler.dialects import shape\n",
    "from iree.compiler.dialects import tensor\n",
    "from iree.compiler.dialects import tosa\n",
    "from iree.compiler.dialects import vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vm.module public @module attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 0, export_funcs = 1, internal_funcs = 1, global_bytes = 0, global_refs = 0, rodatas = 0, rwdatas = 0>} {\n",
      "  vm.func private @matmul(%arg0: !vm.ref<memref<?x?xf32>> loc(unknown), %arg1: !vm.ref<memref<?x?xf32>> loc(unknown), %arg2: !vm.ref<memref<?x?xf32>> loc(unknown)) attributes {ordinal = 0 : i32} {\n",
      "    vm.return loc(\"<stdin>\":3:5)\n",
      "  } loc(\"<stdin>\":3:5)\n",
      "  vm.export @matmul attributes {iree.abi.stub, ordinal = 0 : i32} loc(\"<stdin>\":3:5)\n",
      "} loc(\"<stdin>\":2:3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def testExtraArgsStderr():\n",
    "    # mlir-timing is not special: it just does something and emits to stderr.\n",
    "    with io.StringIO() as buf, contextlib.redirect_stderr(buf):\n",
    "      text = iree.compiler.tools.compile_str(\n",
    "          matmul_expr,\n",
    "          output_format=iree.compiler.tools.OutputFormat.MLIR_TEXT,\n",
    "          extra_args=[\"--mlir-timing\"],\n",
    "          target_backends=iree.compiler.tools.DEFAULT_TESTING_BACKENDS).decode(\n",
    "            \"utf-8\")\n",
    "      stderr = buf.getvalue()\n",
    "    # print(stderr)\n",
    "    print(text)\n",
    "\n",
    "testExtraArgsStderr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export LLVM_INSTALL_DIR=/work/shared/common/llvm-project-gpu\n",
    "# export LD_LIBRARY_PATH=$LLVM_INSTALL_DIR/build/lib:$LD_LIBRARY_PATH\n",
    "# export LD_LIBRARY_PATH=/work/shared/common/usr/local/lib:/work/shared/common/usr/local/lib64:$LD_LIBRARY_PATH\n",
    "# export PATH=/work/shared/common/llvm-project-gpu/build/bin/:$PATH\n",
    "\n",
    "# mlir-opt matmul.mlir \\\n",
    "#     --convert-linalg-to-parallel-loops \\\n",
    "#     --test-gpu-greedy-parallel-loop-mapping \\\n",
    "#     --convert-parallel-loops-to-gpu \\\n",
    "#     --gpu-kernel-outlining \\\n",
    "#     --lower-affine \\\n",
    "#     --convert-scf-to-std \\\n",
    "#     --canonicalize \\\n",
    "#     --pass-pipeline=\"gpu.module(strip-debuginfo,convert-gpu-to-nvvm,gpu-to-cubin)\" --gpu-to-llvm > matmul.mlir.llvm\n",
    "# mlir-translate matmul.mlir.llvm -mlir-to-llvmir > matmul.ll \n",
    "# opt matmul.ll -O3 -S | llc -O3 -o matmul.s \n",
    "# as -o matmul.o matmul.s \n",
    "# clang++ matmul.o -L$LLVM_INSTALL_DIR/build/lib -o exec -lcuda -lmlir_cuda_runtime -lmlir_runner_utils -lmlir_c_runner_utils\n",
    "# ./exec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下降到 affine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
